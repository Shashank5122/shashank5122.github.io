<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Shashank Gupta | Lead AI Engineer/Data Scientist</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header class="hero">
    <img src="assets/profile.jpg" class="profile">
    <h1>Shashank Gupta</h1>
    <h2>Lead Machine Learning Engineer • LLM & Agentic AI Architect</h2>
    <p>
        8+ years architecting and scaling production AI systems across cybersecurity,
        fintech, and enterprise platforms.
    </p>
    <div class="cta">
        <a href="assets/resume.pdf" class="btn">Resume</a>
        <a href="https://github.com/shashank5122" class="btn">GitHub</a>
        <a href="https://linkedin.com/in/shashank-gupta-ai" class="btn">LinkedIn</a>
    </div>
</header>

<section>
    <h2>Professional Summary</h2>
    <p>
        Lead Machine Learning Engineer with deep expertise in LLM-powered systems,
        Retrieval-Augmented Generation (RAG), agent orchestration (LangGraph),
        distributed model serving (vLLM, Triton), and enterprise-grade observability.
        <br><br>
        Delivered measurable impact including:
        <strong>60% GPU cost reduction</strong>,
        <strong>50% redundant API elimination</strong>,
        and <strong>production AI systems at scale</strong>.
    </p>
</section>

<section>
    <h2>Featured AI Systems</h2>

    <div class="card">
        <h3>Production LLM Robocall Automation (HiLABS)</h3>
        <p>
            Architected a LangGraph-powered multi-agent system integrating
            LiveKit, Twilio, structured prompts, dynamic retrieval augmentation,
            and guardrail-based response control.
        </p>
        <p class="highlight">Reduced manual workload by 60%</p>
        <p class="tech">
            LangGraph • LiteLLM • vLLM • Triton • NF4 Quantization • Kubernetes
        </p>
    </div>

    <div class="card">
        <h3>Enterprise RAG System (LSEG)</h3>
        <p>
            Designed scalable Retrieval-Augmented Generation platform using
            Llama 2, optimized embeddings, FAISS indexing, and LangChain orchestration.
        </p>
        <p class="highlight">1st Place – Internal AI Innovation Showcase</p>
        <p class="tech">
            RAG • Llama 2 • FAISS • LangChain • Prompt Engineering
        </p>
    </div>

    <div class="card">
        <h3>Distributed LLM Serving Infrastructure</h3>
        <p>
            Built scalable serving pipelines with batch-parallel inference,
            context-window optimization, and GPU cost monitoring.
        </p>
        <p class="highlight">60% GPU Cost Reduction</p>
        <p class="tech">
            vLLM • Triton • Ray Serve • LiteLLM Observability
        </p>
    </div>

    <div class="card">
        <h3>Real-Time DNS Threat Detection</h3>
        <p>
            Deployed anomaly detection and DGA detection pipelines
            across enterprise DNS traffic using AWS SageMaker.
        </p>
        <p class="tech">
            Autoencoders • Isolation Forest • SageMaker • MLflow
        </p>
    </div>

</section>

<section>
    <h2>Core Expertise</h2>
    <ul class="skills">
        <li>LLMs, RAG & Agentic Workflows (LangGraph)</li>
        <li>Prompt Optimization & Context Engineering</li>
        <li>LLM Observability & Token-Level Cost Monitoring</li>
        <li>Distributed Model Serving (vLLM, Triton)</li>
        <li>Quantization (NF4), PEFT (LoRA/QLoRA)</li>
        <li>AI Governance & Guardrails</li>
        <li>MLOps: MLflow, DVC, CI/CD</li>
        <li>Cloud: AWS SageMaker, GCP</li>
    </ul>
</section>

<footer>
    <p>© 2026 Shashank Gupta | Bangalore, India</p>
</footer>

</body>
</html>
