<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Shashank Gupta | LLM Systems Architect</title>
<link rel="stylesheet" href="style.css">
<meta name="description" content="Lead Machine Learning Engineer with 8 years of experience building distributed LLM systems, RAG platforms, and production-grade AI infrastructure.">
</head>

<body>

<nav>
    <div><strong>Shashank Gupta</strong></div>
    <div>
        <a href="#systems">Systems</a>
        <a href="#impact">Impact</a>
        <a href="#expertise">Expertise</a>
        <a href="#contact">Contact</a>
    </div>
</nav>

<header class="hero">
    <img src="assets/profile.jpg" alt="Shashank Gupta" class="profile">

    <h1>Shashank Gupta</h1>
    <h2>Lead Machine Learning Engineer • LLM & AI Infrastructure Architect</h2>

    <p>
        8 years architecting and scaling production AI systems across
        cybersecurity, fintech, and enterprise platforms.
        <br><br>
        Specialized in distributed LLM serving (vLLM, Triton), RAG architectures,
        LangGraph agent orchestration, token-level observability,
        and GPU cost optimization.
    </p>

    <div>
        <a href="assets/resume.pdf" class="btn">Resume</a>
        <a href="https://github.com/shashank5122" class="btn">GitHub</a>
        <a href="https://linkedin.com/in/shashank-gupta-ai" class="btn">LinkedIn</a>
    </div>
</header>

<section id="systems">
    <h2>Selected AI Systems</h2>

    <div class="card">
        <h3>Production LLM Robocall Automation – HiLABS</h3>
        <p>
            Architected a LangGraph-powered multi-agent system integrating LiveKit,
            Twilio, structured prompts, retrieval augmentation, tool-calling workflows,
            and guardrail-based response control.
        </p>
        <p class="highlight">Reduced manual verification workload by 60%</p>
        <p class="tech">
            LangGraph • LiteLLM • vLLM • Triton • NF4 Quantization • Kubernetes
        </p>
    </div>

    <div class="card">
        <h3>Enterprise RAG Platform – LSEG</h3>
        <p>
            Designed and led development of a Retrieval-Augmented Generation system
            using Llama 2, optimized embedding pipelines, FAISS indexing,
            and LangChain orchestration.
        </p>
        <p class="highlight">1st Place – Internal AI Innovation Showcase</p>
        <p class="tech">
            RAG • Llama 2 • FAISS • LangChain • Prompt Engineering
        </p>
    </div>

    <div class="card">
        <h3>Distributed LLM Serving Infrastructure</h3>
        <p>
            Built scalable serving pipelines with NF4-quantized models,
            batch-parallel inference, context-window optimization,
            and GPU cost monitoring.
        </p>
        <p class="highlight">Achieved 60% GPU Cost Reduction</p>
        <p class="tech">
            vLLM • Triton • Ray Serve • LiteLLM Observability
        </p>
    </div>

    <div class="card">
        <h3>Real-Time DNS Threat Detection – FireEye</h3>
        <p>
            Architected ML-driven DGA detection and DNS tunneling systems,
            deployed via AWS SageMaker with structured MLOps pipelines.
        </p>
        <p class="tech">
            Autoencoders • Isolation Forest • SageMaker • MLflow
        </p>
    </div>
</section>

<section id="impact">
    <h2>Impact Metrics</h2>
    <div class="metrics">
        <div class="metric-box">
            <h3>60%</h3>
            <p>GPU Cost Reduction</p>
        </div>
        <div class="metric-box">
            <h3>50%</h3>
            <p>Redundant API Elimination</p>
        </div>
        <div class="metric-box">
            <h3>60%</h3>
            <p>Manual Workflow Reduction</p>
        </div>
        <div class="metric-box">
            <h3>15%</h3>
            <p>Anomaly Detection Improvement</p>
        </div>
    </div>
</section>

<section id="expertise">
    <h2>Core Expertise</h2>

    <div class="skills">
        <div>LLMs, RAG & Agentic Workflows (LangGraph)</div>
        <div>Prompt Optimization & Context Engineering</div>
        <div>LLM Observability & Token-Level Cost Monitoring</div>
        <div>Distributed Model Serving (vLLM, Triton)</div>
        <div>Quantization (NF4), PEFT (LoRA/QLoRA)</div>
        <div>AI Governance & Guardrails</div>
        <div>MLOps: MLflow, DVC, CI/CD</div>
        <div>AWS SageMaker & Google Cloud</div>
    </div>
</section>

<section id="contact">
    <h2>Contact</h2>
    <p>
        Bangalore, India <br>
        shashank5122@gmail.com <br>
        <a href="https://linkedin.com/in/shashank-gupta-ai">linkedin.com/in/shashank-gupta-ai</a>
    </p>
</section>

<footer>
    © 2026 Shashank Gupta — Built with GitHub Pages
</footer>

</body>
</html>
